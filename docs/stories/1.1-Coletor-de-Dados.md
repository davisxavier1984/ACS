# Estória 1.1: Desenvolvimento do Coletor de Dados Estadual Multi-Competência

**Épico:** Plataforma de Coleta e Armazenamento de Dados de ACS  
**Prioridade:** Alta  
**Estimativa:** 8 pontos  
**Sprint:** Sprint 1

## Resumo
Como um gestor estadual de saúde, eu quero um coletor automatizado de dados de ACS que processe múltiplas competências para todos os municípios de um estado, para que eu tenha uma base de dados local confiável e atualizada para análises posteriores.

## Contexto e Justificativa
O sistema atual requer consultas individuais à API do Ministério da Saúde para cada município e competência, resultando em demora e instabilidade nas análises estaduais. Este coletor criará uma base de dados local (SQLite) que permitirá análises rápidas e offline, essencial para a Visão Estadual do dashboard.

## Critérios de Aceitação

### CA1: Interface de Linha de Comando
- [x] O script `coletor_dados.py` aceita argumentos obrigatórios:
  - `--uf` ou `-u`: Código da UF (ex: "PE", "SP")
  - `--competencias` ou `-c`: Lista de competências no formato "AAAA/MM" (ex: "2024/01,2024/02,2024/03")
- [x] Exemplo de execução: `python coletor_dados.py --uf PE --competencias "2024/01,2024/02,2024/03"`
- [x] Exibe help detalhado com `--help`
- [x] Valida argumentos de entrada (UF válida, formato de competência correto)

### CA2: Processamento Sequencial de Dados
- [ ] Itera por todos os municípios da UF especificada usando a API do IBGE
- [ ] Para cada município, processa todas as competências fornecidas
- [ ] Reutiliza a lógica de cálculo existente em `acs_analyzer.py`
- [ ] Mantém compatibilidade com os métodos existentes de extração de métricas ACS

### CA3: Política de Retentativas e Tratamento de Erros
- [ ] Implementa retry policy: 3 tentativas com pausa progressiva (1s, 3s, 5s)
- [ ] Registra erros detalhados em arquivo de log `logs/coletor_dados_UF_TIMESTAMP.log`
- [ ] Continua processamento mesmo se alguns municípios falharem
- [ ] Gera relatório final com estatísticas de sucesso/falha

### CA4: Armazenamento em Banco de Dados
- [ ] Salva dados consolidados em `data/dados_{UF}.sqlite`
- [ ] Estrutura de tabelas otimizada para consultas da Visão Estadual:
  - Tabela `municipios`: dados básicos dos municípios
  - Tabela `acs_metricas`: métricas ACS por município/competência
  - Índices otimizados para consultas por UF e competência
- [ ] Implementa upsert (insert ou update) para evitar duplicação
- [ ] Mantém histórico de atualizações com timestamp

### CA5: Indicadores de Progresso
- [ ] Exibe progresso em tempo real usando barra de progresso (tqdm ou similar)
- [ ] Mostra: município atual, competência atual, progresso percentual
- [ ] Estima tempo restante baseado na velocidade média de processamento
- [ ] Exibe estatísticas ao final: total processado, sucessos, falhas, tempo total

### CA6: Estrutura de Diretórios
- [ ] Cria automaticamente a estrutura inicial do projeto:
  ```
  /
  ├── pages/           # Páginas Streamlit (futuras)
  ├── data/           # Bancos de dados SQLite
  ├── logs/           # Arquivos de log
  └── requirements.txt # Dependências do projeto
  ```
- [ ] Verifica e cria diretórios que não existem
- [ ] Gera `requirements.txt` com todas as dependências necessárias

### CA7: Centralização da Lógica de API
- [ ] A lógica de API está centralizada em `saude_api.py` com:
  - Headers padronizados para simular browser
  - Tratamento de timeout e erros de conexão
  - Rate limiting para evitar sobrecarga da API
  - Métodos específicos para consulta de municípios e dados ACS
- [ ] Implementa cache temporário de requisições para evitar calls duplicados
- [ ] Standardiza formato de retorno de dados da API

## Detalhes Técnicos

### Dependências Requeridas
```txt
streamlit>=1.28.0
requests>=2.31.0
pandas>=2.0.0
plotly>=5.15.0
tqdm>=4.65.0
sqlite3 (built-in)
argparse (built-in)
logging (built-in)
```

### Estrutura do Banco de Dados SQLite

#### Tabela: municipios
```sql
CREATE TABLE municipios (
    id INTEGER PRIMARY KEY,
    codigo_ibge TEXT UNIQUE NOT NULL,
    nome TEXT NOT NULL,
    uf TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### Tabela: acs_metricas
```sql
CREATE TABLE acs_metricas (
    id INTEGER PRIMARY KEY,
    municipio_id INTEGER NOT NULL,
    competencia TEXT NOT NULL,
    quantidade_teto INTEGER,
    quantidade_credenciado INTEGER,
    quantidade_pago INTEGER,
    total_deveria_receber REAL,
    total_recebido REAL,
    total_perda REAL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (municipio_id) REFERENCES municipios(id),
    UNIQUE(municipio_id, competencia)
);
```

#### Índices para Performance
```sql
CREATE INDEX idx_acs_uf_competencia ON acs_metricas(municipio_id, competencia);
CREATE INDEX idx_municipios_uf ON municipios(uf);
```

### Arquitetura do Coletor

#### Fluxo Principal
1. **Validação de Argumentos**: Verifica UF e formato das competências
2. **Inicialização**: Cria estrutura de diretórios e banco de dados
3. **Obtenção de Municípios**: Consulta API IBGE para lista de municípios da UF
4. **Loop Principal**: Para cada município × competência:
   - Consulta API Ministério da Saúde
   - Processa dados usando `acs_analyzer.py`
   - Salva no banco SQLite
   - Atualiza progresso
5. **Finalização**: Gera relatório e estatísticas finais

#### Tratamento de Erros por Nível
- **Nível API**: Retry com backoff exponencial
- **Nível Município**: Log erro e continua para próximo
- **Nível Competência**: Log erro e continua para próxima
- **Nível Sistema**: Salva estado atual e permite restart

### Reutilização de Código Existente

#### Integração com `acs_analyzer.py`
```python
from acs_analyzer import ACSAnalyzer

# Reutilizar lógica existente
analyzer = ACSAnalyzer()
metricas = analyzer.extrair_metricas_acs(dados_api)
```

#### Integração com `saude_api.py`
```python
from saude_api import SaudeAPI

# Usar API centralizada
api = SaudeAPI()
dados = api.obter_dados_municipio(uf, municipio, competencia)
```

## Critérios de Aceite Técnicos

### Performance
- [ ] Processa pelo menos 5 municípios por minuto
- [ ] Usa no máximo 512MB de RAM durante execução
- [ ] Implementa rate limiting (máximo 2 requests/segundo para API)

### Qualidade de Código
- [ ] Cobertura de testes unitários > 80%
- [ ] Docstrings em todas as funções públicas
- [ ] Type hints em todas as assinaturas de função
- [ ] Código segue padrões PEP 8

### Robustez
- [ ] Suporta interrupção e retomada (graceful shutdown)
- [ ] Valida integridade dos dados antes de salvar
- [ ] Implementa backup automático do banco antes de atualizações

## Definição de Pronto (DoD)
- [ ] Todos os critérios de aceitação validados
- [ ] Testes unitários implementados e passando
- [ ] Documentação técnica atualizada
- [ ] Code review aprovado pelo tech lead
- [ ] Testado com pelo menos 2 UFs diferentes
- [ ] Performance validada com carga real (>100 municípios)

## Notas de Implementação

### Ordem de Desenvolvimento Sugerida
1. Estrutura básica do CLI e validação de argumentos
2. Criação do banco de dados e tabelas
3. Integração com APIs existentes (`saude_api.py`, `acs_analyzer.py`)
4. Loop principal de processamento
5. Sistema de retry e tratamento de erros
6. Indicadores de progresso e logging
7. Testes e otimizações

### Casos de Teste Prioritários
1. **Teste com município conhecido**: Abaré/PE, competência 2025/06
2. **Teste com UF pequena**: Acre (22 municípios)
3. **Teste com múltiplas competências**: 3 meses consecutivos
4. **Teste de interrupção**: Cancelar execução e verificar consistência
5. **Teste de retry**: Simular falhas de API

### Considerações de Produção
- Executar preferencialmente em horários de menor carga da API (madrugada)
- Monitorar logs para identificar padrões de falha
- Manter backups regulares dos bancos SQLite
- Considerar paralelização futura (mas implementar sequencial primeiro)

## Riscos e Mitigações

| Risco | Probabilidade | Impacto | Mitigação |
|-------|---------------|---------|-----------|
| API instável do Min. Saúde | Alta | Alto | Retry robusto, logs detalhados |
| Performance lenta | Média | Médio | Rate limiting, otimização de queries |
| Corrupção de dados | Baixa | Alto | Validação rigorosa, backups |
| Mudança na API | Baixa | Alto | Abstração na camada de API |

## Entregáveis
1. Script `coletor_dados.py` funcional
2. Banco SQLite com dados coletados
3. Documentação de uso (README seção)
4. Logs de execução demonstrando funcionalidade
5. Testes automatizados básicos